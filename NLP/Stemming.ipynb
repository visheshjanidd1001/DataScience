{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca355584-fcb8-4caa-a62a-65768a002047",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is an important text-processing technique that reduces words to their base or root form by removing prefixes and suffixes. This process standardizes words which helps to improve the efficiency and effectiveness of various natural language processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c54111-5206-4769-b062-1f04c9680627",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification problem\n",
    "## Comments of product is a positive review or negative review\n",
    "## Reviews --> Eating,Eat,Eaten [going,gone,goes] --> Go\n",
    "\n",
    "words = [\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024c931-b74b-4480-a966-dff782377010",
   "metadata": {},
   "source": [
    "## portestemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb217b3f-d05e-4c32-8811-f7a742bd66dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3dc421b-e571-4f38-ae05-bd2d71761ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8053f5e1-ff14-41af-b888-91329c4f0380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalized---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59d2a986-2892-49be-a0ff-7d6cf3e61107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"congratulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05d169c5-1a38-44a4-81a7-a6a96472dce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"sitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e56ce4-5a2d-40f0-8d7f-0532d0fd416f",
   "metadata": {},
   "source": [
    "## RegexpStemmer class\n",
    "NLTK has regexpstemmer class with the help of which we can easily implement regular expression stemmer algorithms. It basically takes a singular regular expression and removes any prefix and suffix that matches the expression. Let us see an example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6c4dcac-bf79-4e60-82a4-8cd4a5152beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc62efa-187a-46e8-a092-45e105e37a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "496f3911-7264-4451-94b4-c8f222f4a2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"eating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36ac746f-4c8e-472c-9c83-794198b73434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"ingeating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90ea44-1792-4e7e-9bdf-9cdbe1452e0a",
   "metadata": {},
   "source": [
    "## SnowBall Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d1c39b8-5498-4b90-bf9a-c53f06665a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b35fedb-badf-4803-97d2-bef88cc8f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballstemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6206aefc-4251-48bf-a05e-8f6624de1604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eat\n",
      "eats-->eat\n",
      "eaten-->eaten\n",
      "writing-->write\n",
      "writes-->write\n",
      "programming-->program\n",
      "programs-->program\n",
      "history-->histori\n",
      "finally-->final\n",
      "finalized-->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"-->\"+snowballstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "599dd8a9-4f79-4596-8bc9-48c019138128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39fbc855-fa08-4f47-a57f-be4abcfe0fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem(\"fairly\"),snowballstemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16149111-73e3-4929-a058-905f2700d88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
